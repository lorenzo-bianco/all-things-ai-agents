# User report moderation agent

AI-powered workflow that processes every user report on a marketplace listing, aggregates report history, enriches context, and returns a final enforcement action. It's very easy to implement and it might make you able to save money if you are currently moderating content with humans or with linear, simple logic-driven workflows.

## ðŸ‘‰ What this agent does

This agent receives a reported item (listing) and automatically decides what to do with it by combining:
	â€¢	the current report received
	â€¢	the history of reports for that item/user (from Google Sheets, DB, or any data source)
	â€¢	the reported userâ€™s attributes
	â€¢	the content attributes
	â€¢	the userâ€™s past messages (if provided)

The AI Agent then produces a final outcome:
	â€¢	ignore â†’ reports not credible or false positive
	â€¢	deactivate_content â†’ content violates rules
	â€¢	deactivate_user â†’ severe abuse, repeat offender, or high-risk behavior

## ðŸ‘‰ High-level flow

### 1. Input

The workflow is triggered every time a report is received.
Input may come from:
	â€¢	a webhook POST from your platform
	â€¢	a Google Sheet row created/updated
	â€¢	a manual payload (debug/testing)

The payload must include at least:
```
{
  "item_id": "",
  "reported_user_id": "",
  "reporter_user_id": "",
  "report_type": "",
  "report_reason": "",
  "metadata": { ... }
}
```
### 2. Data enrichment

Before calling the AI agent, the workflow gathers context:
	
â€¢	Fetch report history for the same item/user

â€¢	Fetch user attributes (past behaviour, trust signals, violations)

â€¢	Fetch item details (title, description, category, etc.)

â€¢	Fetch user messages (optional, if relevant for abuse checks)

This enriched payload becomes the decision surface.

### 3. AI Moderation Decision

The LLM agent receives a consolidated JSON containing:

â€¢	the incoming report

â€¢	all historical reports

â€¢	user data

â€¢	content data
	
â€¢	messages

â€¢	moderation rules

The agent must output:
```
{
  "outcome": "ignore | deactivate_content | deactivate_user",
  "rationale": "string"
}
```
You may extend the output schema in the prompt as needed (severity score, confidence, etc.).

### 4. Action Execution

Workflow nodes perform operational tasks:
	â€¢	Log the decision (analytics, audits, continuous tuning)
	â€¢	Send API call to apply the enforcement:
	â€¢	deactivate item
	â€¢	deactivate user
	â€¢	or do nothing
	â€¢	Optional notifications
	â€¢	internal team alerts
	â€¢	user communication

### ðŸ‘‰ Example input

```
{
  "item_id": "A1234",
  "reported_user_id": "U5678",
  "report_type": "scam",
  "report_reason": "suspicious payment link",
  "metadata": {
    "message_id": "M9123"
  }
}
```

### ðŸ‘‰ Example AI output

```
{
  "action": "<ignore | disable item | disable user>",
  "reason": "<short, clear explanation of why this action was selected>",
  "reports_summary": [
    {
      "topic": "...",
      "content": "...",
      "reporter": "..."
    }
  ],
  "item_id": "{{ $json.item_id }}"
}
```

## ðŸ‘‰ When to use this agent

Use it when you need to:

â€¢	process all incoming reports automatically
  
â€¢	enforce actions consistently
  
â€¢	remove bias or manual inconsistencies

â€¢	scale trust & safety without proportional headcount

â€¢	create a clean, auditable moderation pipeline

## ðŸ‘‰ Requirements

â€¢	An event source (webhook, sheet, or queue)

â€¢	DB or Sheet containing report history (optional but recommended)

â€¢	API endpoints to deactivate items/users

â€¢	LLM provider (OpenAI, Anthropic, Gemini, etc.)

â€¢	n8n (or similar) as the orchestration layer
