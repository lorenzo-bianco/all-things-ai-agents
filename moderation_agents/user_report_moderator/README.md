# User Report Moderation Agent

This is a plug-and-play, AI-powered moderation agent that proactively starts whenever a user submits a report.

It acts immediately to address issues raised by users, preventing a single bad experience from spreading to others.

Once triggered, the agent fetches all relevant context on demand (item report history, user attributes, item details, user message history, and any other data sources you connect) and returns a single enforcement action with a clear, auditable rationale.

The result is a consistent and scalable moderation pipeline that keeps your marketplace safe and clean without adding operational overhead.

## ðŸ‘‰ Repository structure 

```
user_report_moderator/
â”‚
â”œâ”€â”€ README.md
â”‚   â†’ Overview of the agent, high-level behaviour, examples.
â”‚
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ workflow_n8n.json
â”‚   â”‚   â†’ The full n8n workflow template, ready to import.
â”‚   â””â”€â”€ README.md
â”‚       â†’ Setup instructions: how to use and adapt the workflow engine.
â”‚
â”œâ”€â”€ prompt.md
â”‚   â†’ Contains both prompts used by the LLM:
â”‚       1. System prompt (identity + rules + constraints)
â”‚       2. Execution prompt (the step-by-step moderation logic)
â”‚
â””â”€â”€ use_cases.md
    â†’ Practical examples showing how the agent behaves
      with different scenarios, inputs, and expected outputs.
```

## ðŸ‘‰ High-level flow

**1. Input**

Triggered whenever a report arrives through any of the supported sources:

â€¢	Webhook POST from your platform

â€¢	New row in a Google Sheet

â€¢	DB event or message queue

â€¢	Manual payload for debugging

Minimum recommended fields:

```
{
  "item_id": "",
  "reported_user_id": "",
  "reporter_user_id": "",
  "report_type": "",
  "report_reason": "",
  "metadata": { ... }
}
```
â¸»

**2. Context Gathering + Moderation Decision**

The agent receives the input payload and then pulls additional context on demand using the available tools.

Depending on the specific scenario, it may fetch:

â€¢	Item report history (other reports about the same item)

â€¢	User attributes (behaviour, trust signals, past violations of the reported item owner)

â€¢	Item details (description, metadata, category, content signals)

â€¢	User message history (if your product has a chat)

â€¢	Any other datasource you connect


The agent decides what to fetch and when to fetch it, based on the logic defined in the prompt.

After combining the collected signals, the agent outputs one final action:

```
{
  "action": "ignore | disable_item | disable_user",
  "reason": "string"
}
```

You can extend the schema (severity, confidence score, flags, metadata) directly inside the prompt.

â¸»

**3. Action Execution**

The workflow then performs the operational steps:

â€¢	Calls your API to enforce the decision

â€¢	Logs the decision (for analytics, monitoring, audits purposes)

â€¢	Sends optional notifications (internal alert or external user communication)

â¸»

## ðŸ‘‰ Example input
```
{
  "item_id": "A1234",
  "reported_user_id": "U5678",
  "report_type": "scam",
  "report_reason": "suspicious payment link",
  "metadata": {
    "message_id": "M9123"
  }
}
```

## ðŸ‘‰ Example AI output

```
{
  "action": "disable_item",
  "reason": "Multiple consistent reports and suspicious off-platform contact",
  "reports_summary": [
    {
      "topic": "scam",
      "content": "asked for external payment link",
      "reporter": "user_11"
    }
  ],
  "item_id": "A1234"
}
```

## ðŸ‘‰ Requirements
	
â€¢	Event source (webhook / Sheets / DB / queue)

â€¢	Datasource for historical reports (recommended)

â€¢	Enforcement API endpoints

â€¢	LLM provider (OpenAI, Anthropic, Gemini, etc.)

â€¢	n8n (or similar orchestration layer)
