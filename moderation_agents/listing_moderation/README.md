# ğŸ“„ Listing Moderation Agent

AI Agent that evaluates listings metadata to detect prohibited content, scams, inconsistencies or low-quality patterns before publication.
It helps reduce manual review workload and keeps the marketplace safe and trustworthy.

â¸»

ğŸ¯ Problems

1. User-generated listings often contain misleading info, risky content or policy violations
2. Manual moderation is slow, inconsistent and expensive.
3. Bad listings reaching users damage trust and conversion.

This agent aims to automate the first moderation layer so humans handle only real edge cases.

â¸»

ğŸ§© Context

â€¢	Runs when a listing is created or edited

â€¢	Useful for both pre and post publication checks

â€¢	Supports trust and safety content teams

â€¢	Designed for high-volume marketplaces

â¸»

ğŸ“¥ Inputs & Outputs (overview)

â†’ Inputs

â€¢	title

â€¢	description

â€¢	metadata (title, description, price, location, listing type, characteristics, etc)

â€¢	optional: user signals (user related attributes, user marketplace latest interactions, etc)

â†’ Outputs

â€¢	decision: approve, reject, manual_review
  
â€¢	reason: explanation of why
  
â€¢	suggestions: optional improvements

â¸»

âš™ï¸ How it works

1.	Reads metatadata and context

2.	Identifies risky or prohibited 

3.	Checks coherence between fields

4.	Evaluates clarity and completeness

5.	Produces a structured moderation result
	
6.	Passes output to automation (n8n) for routing

â¸»

ğŸ“‚ Files in this folder

â€¢	system_prompt.md â€” core moderation logic

â€¢	examples.md â€” sample inputs/outputs

â€¢	workflow_n8n.json â€” automation flow

â€¢	evaluation.md â€” criteria for quality

â€¢	schema.md â€” input/output contract

â¸»

âš ï¸ Limitations

â€¢	Needs webhook events or manual inputs to run

â€¢	Ambiguous listings may require manual review

â€¢	Model accuracy depends on text completeness

â¸»

ğŸš€ Next steps

â€¢	Add images as another moderation input

â€¢	Add more risk signals

â€¢	Expand evaluation set

â€¢	Improve suggestions for low-quality text
