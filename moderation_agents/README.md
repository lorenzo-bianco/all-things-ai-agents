## ğŸ›¡ï¸ **Moderation agents for marketplace content quality and safety**

These AI Agents can be used to keep product spaces clean and safe.
They can detect risky content, reduce manual review load and improve content quality before publication.

They are great tools for marketplace environments where high-volume user-generated content requires fast, consistent and scalable moderation.

### ğŸ” **Whatâ€™s inside**

â†’ [user report_moderator/](https://github.com/lorenzo-bianco/all-things-ai-agents/tree/main/moderation_agents/user_report_moderator)

â€¢ User Report Moderation Agent: analyzes user reports, aggregates past flags and decides whether to ignore, deactivate the content or deactivate the user.

â†’ [listing_moderator/](https://github.com/lorenzo-bianco/all-things-ai-agents/tree/main/moderation_agents/listing_moderator)

â€¢ Listing Moderation Agent: checks listing titles, descriptions and metadata to detect prohibited content, scams, low quality or inconsistencies.

â†’ [chat_moderator/](https://github.com/lorenzo-bianco/all-things-ai-agents/tree/main/moderation_agents/chat_moderator)

â€¢ Chat Moderation Agent: flags harmful messages, suspicious patterns and unsafe buyerâ€“seller interactions.

### ğŸ› ï¸ **Structure of each agent**

Each agent folder follows a consistent structure:

â€¢	README.md â€“ business context and how the agent works

â€¢	engine â€“ folder with automation setup and json template

â€¢	prompt.md â€“ core logics for the AI Agent

â€¢	use_cases.md â€“ real applications of the agent

### ğŸ‘‰ **Why these agents matter**

Moderation issues harm trust, increase operational cost and slow down the publishing flow.
These agents are built to:

â€¢	reduce manual review time

â€¢	catch risky cases earlier

â€¢	improve content quality before it reaches users

â€¢	standardize decision logic

â€¢	support trust & safety teams with scalable automation
