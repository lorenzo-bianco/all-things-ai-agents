**Moderation & Content Safety**

These AI Agents can be used to keep product spaces clean and safe.
They can detect risky content, reduce manual review load and improve content quality before publication.

They are great tools for marketplace environments where high-volume user-generated content requires fast, consistent and scalable moderation.

⸻

**What’s inside**

• Listing Moderation Agent: checks listing titles, descriptions and metadata to detect prohibited content, scams, low quality or inconsistencies.

→ listing_moderation/

• Chat Moderation Agent: flags harmful messages, suspicious patterns and unsafe buyer–seller interactions.

→ chat_moderation/

⸻

**Why these agents matter**

Moderation issues harm trust, increase operational cost and slow down the publishing flow.
These agents are built to:

•	reduce manual review time

•	catch risky cases earlier

•	improve content quality before it reaches users

•	standardize decision logic

•	support trust & safety teams with scalable automation

⸻

**Structure of each agent**

Each agent folder follows a consistent structure:

•	README.md – business context and how the agent works

•	system_prompt.md – core logic

•	examples.md – input/output samples

•	workflow_n8n.json – automation setup

•	evaluation.md – criteria for quality and reliability

•	schema.md – input/output contract
